{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning at Fireside\n",
    "scott sadlo, isabella seeman, joseph nelson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    "[Jupyter Notebooks](https://en.wikipedia.org/wiki/Project_Jupyter) provide an amazing interface for collaborating on and sharing code and the process of data analaysis. \n",
    "\n",
    "### Pandas\n",
    "[Pandas](https://pandas.pydata.org) is a library for easy manipulation and analysis of large sets of data.\n",
    "\n",
    "### SKLearn\n",
    "[SKLearn](https://scikit-learn.org/) provides an abundance of machine learning tools and algorithms that are both powerful and easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Outgoing Responses\n",
    "\n",
    "One of the common problems faced by staffers on The Hill is pairing incoming constituent messages with outgoing responses. What follows is an investigation into various techniques for automatically predicting the appropriate response for each incoming message.\n",
    "\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "We start off by reading all of the data into a Pandas data frame and then do some rudimentary data analysis. For the purposes of privacy, our data set is not actually constituent mail here, it's actually sentences from scientific articles, but the methodology is the same. These messages have been pre-classified as follows:\n",
    "\n",
    "* AIMX The specific research goal of the paper \n",
    "* OWNX The authorâ€™s own work, e.g. methods, results, conclusions\n",
    "* CONT Contrast, comparison or critique of past work\n",
    "* BASE Past work that provides the basis for the work in the article.\n",
    "* MISC Any other sentences\n",
    "\n",
    "The class can be thought of as a pointer to an outgoing response, and the sentence can be considered an incoming constituent message.\n",
    "\n",
    "Note: This data comes from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Sentence+Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Prepare the Pandas/Jupyter environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and Clean Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3118, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, re \n",
    "from io import StringIO\n",
    "all_files = glob.glob(\"./data/*.txt\")\n",
    "all_lines = []\n",
    "for f in all_files:\n",
    "    r = open(f)\n",
    "    for l in r.readlines():\n",
    "        # some lines use ' ', and '--' as separators, here we\n",
    "        # standardize these at '\\t'\n",
    "        all_lines.append(re.sub(r'^(AIMX|OWNX|CONT|BASE|MISC)( |-)+', '\\\\1\\t', l))\n",
    "\n",
    "data = StringIO('\\n'.join(all_lines))\n",
    "df = pd.read_csv(data, delimiter='\\t', names=['outgoing', 'incoming'], header=None)\n",
    "\n",
    "# strip out #### marker lines ####\n",
    "df = df.loc[~df.outgoing.str.contains('#')]\n",
    "\n",
    "# clean up NaN lines in 'incoming'\n",
    "df['incoming'] = df['incoming'].astype(str)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some basic stats on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outgoing</th>\n",
       "      <th>incoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3118</td>\n",
       "      <td>3118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MISC</td>\n",
       "      <td>The observations received by the learning algorithm often have some inherent temporal dependence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1826</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outgoing  \\\n",
       "count   3118      \n",
       "unique  5         \n",
       "top     MISC      \n",
       "freq    1826      \n",
       "\n",
       "                                                                                                incoming  \n",
       "count   3118                                                                                              \n",
       "unique  1323                                                                                              \n",
       "top     The observations received by the learning algorithm often have some inherent temporal dependence  \n",
       "freq    4                                                                                                 "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a peek at the first few messages in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outgoing</th>\n",
       "      <th>incoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>this study was designed to assess sex-related differences in the selection of an appropriate strategy when facing novelty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>the exploration task was followed by a visual discrimination task  and the responses were analyzed using signal detection theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>during exploration women selected a local searching strategy in which the metric distance between what is already known and what is unknown was reduced  whereas men adopted a global strategy based on an approximately uniform distribution of choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OWNX</td>\n",
       "      <td>women's exploratory behavior gives rise to a notion of a secure base warranting a sense of safety while men's behavior does not appear to be influenced by risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  outgoing  \\\n",
       "1  OWNX      \n",
       "2  OWNX      \n",
       "3  OWNX      \n",
       "4  OWNX      \n",
       "5  OWNX      \n",
       "\n",
       "                                                                                                                                                                                                                                                   incoming  \n",
       "1  this study was designed to assess sex-related differences in the selection of an appropriate strategy when facing novelty                                                                                                                                 \n",
       "2  nan                                                                                                                                                                                                                                                       \n",
       "3  the exploration task was followed by a visual discrimination task  and the responses were analyzed using signal detection theory                                                                                                                          \n",
       "4  during exploration women selected a local searching strategy in which the metric distance between what is already known and what is unknown was reduced  whereas men adopted a global strategy based on an approximately uniform distribution of choices  \n",
       "5  women's exploratory behavior gives rise to a notion of a secure base warranting a sense of safety while men's behavior does not appear to be influenced by risk                                                                                           "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data \n",
    "\n",
    "\n",
    "Fundamentally what we're trying to do here is take a set of known data (incoming messages or X) and predict a bit of unknown data (a specific outgoing message) from a field of other known data (outgoing messages or y). To do so using supervised learning, the entire corpus of data is typically split into training and testing datasets. Here we do just that, using 80% of the data for training, and 20% for testing. We also keep all of the data together for our look at Support-vector Machines.\n",
    "\n",
    "Again, X is the data being used to predict the y labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "incoming_X_train = df[msk].incoming.values\n",
    "outgoing_y_train = df[msk].outgoing.values\n",
    "\n",
    "incoming_X_test = df[~msk].incoming.values\n",
    "outgoing_y_test = df[~msk].outgoing.values\n",
    "\n",
    "incoming_X_all = df.incoming.values\n",
    "outgoing_y_all = df.outgoing.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the Messages\n",
    "\n",
    "In order for our sentences to be useful mathematically, we need to convert them into vectors, or sequences of numbers, that represent the vocabulary of our messages in different ways. We've put a couple of functions here to allow us to easily test different algorithms with a variety of vector representations.\n",
    "\n",
    "\n",
    "For more on vectorizers, checkout [Hacking Scikit-Learnâ€™s Vectorizers](https://towardsdatascience.com/hacking-scikit-learns-vectorizers-9ef26a7170af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "\n",
    "def call_with_transforms(vect, X_train, X_test, callable):\n",
    "    dtm_train = vect.fit_transform(X_train)\n",
    "    dtm_test = None\n",
    "    if X_test is not None:\n",
    "        dtm_test = vect.transform(X_test)\n",
    "    callable(dtm_train, dtm_test, vect)\n",
    "    \n",
    "def try_vectorizers(callable, X_train, X_test):\n",
    "\n",
    "    print('CountVectorizer')    \n",
    "    vect = CountVectorizer(ngram_range=(1, 10), stop_words='english', min_df=1)\n",
    "    call_with_transforms(vect, X_train, X_test, callable)\n",
    "    \n",
    "    print('')\n",
    "    print('TfidfVectorizer')    \n",
    "    vect = TfidfVectorizer(ngram_range=(1, 10), stop_words='english', min_df=1)\n",
    "    call_with_transforms(vect, X_train, X_test, callable)\n",
    "    \n",
    "    print('')\n",
    "    print('HashingVectorizer')    \n",
    "    vect = HashingVectorizer(non_negative=True, stop_words='english')\n",
    "    call_with_transforms(vect, X_train, X_test, callable)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Best Algorithm\n",
    "\n",
    "We now take a look at a few common machine learning algorithms that are well suited for the tasks of text classification to find which produces the best results on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "[Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) is a popular text classification method that makes use of probabilities. As it turns out this method, of those we try here, produces the best results on our real data as well as the sample data used by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "0.7728706624605678\n",
      "\n",
      "TfidfVectorizer\n",
      "0.8233438485804416\n",
      "\n",
      "HashingVectorizer\n",
      "0.6845425867507886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "def naive_bayes(dtm_train, dtm_test, vect):\n",
    "    # use Naive Bayes to predict term\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(dtm_train, outgoing_y_train)\n",
    "    y_pred_class = nb.predict(dtm_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    print(metrics.accuracy_score(outgoing_y_test, y_pred_class))\n",
    "    \n",
    "try_vectorizers(naive_bayes, incoming_X_train, incoming_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support-vector Machine (SVM)\n",
    "[Support-vector Machine](https://en.wikipedia.org/wiki/Support-vector_machine) is another popular text classification algorithm, but it is geometric rather than probablistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "0.8595253367543297\n",
      "{'C': 10.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "TfidfVectorizer\n",
      "0.8617703656189866\n",
      "{'C': 10.0, 'gamma': 1.0, 'kernel': 'sigmoid'}\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "HashingVectorizer\n",
      "0.8627325208466966\n",
      "{'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "def SVM(dtm_train, dtm_test, vect):\n",
    "    clf = svm.SVC()\n",
    "    gamma_range = 10.**np.arange(-5, 2)\n",
    "    C_range = 10.**np.arange(-2, 3)\n",
    "    kernel_range = ['rbf', 'sigmoid', 'linear', 'poly']\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range, kernel=kernel_range)\n",
    "    grid = GridSearchCV(clf, param_grid, cv=10, scoring='accuracy')\n",
    "    grid.fit(dtm_train, outgoing_y_all)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_estimator_)\n",
    "try_vectorizers(SVM, incoming_X_all, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "[Random Forest](https://en.wikipedia.org/wiki/Random_forest) classifiers build decision trees from random feature subsets to determine the best features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "Best score = 0.785426731078905\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto'}\n",
      "RandomForest Cross_Val Score:\t 0.7846641940678634\n",
      "Train/Test RandomForest Score:\t 0.831230283911672\n",
      "\n",
      "TfidfVectorizer\n",
      "Best score = 0.789049919484702\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto'}\n",
      "RandomForest Cross_Val Score:\t 0.7814464453802886\n",
      "Train/Test RandomForest Score:\t 0.8170347003154574\n",
      "\n",
      "HashingVectorizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def random_forest(dtm_train, dtm_test, vect):\n",
    "    rf_grid = RandomForestClassifier(random_state=99, n_jobs=50)\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth' : [None,2,5,8],\n",
    "        'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "        'class_weight' : ['balanced', None]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(rf_grid, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    #Fit the grid search to X, and y.\n",
    "    grid.fit(dtm_train, outgoing_y_train)\n",
    "\n",
    "    params = grid.best_params_\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf_model = rf.fit(dtm_train, outgoing_y_train)\n",
    "    y_pred = rf.predict(dtm_test)\n",
    "\n",
    "    print(\"Best score =\", grid.best_score_)\n",
    "    print(\"RandomForest Cross Validation Score:\\t\", cross_val_score(rf, dtm_train, outgoing_y_train, cv=5).mean())\n",
    "    print(\"Train/Test RandomForest Score:\\t\", rf.score(dtm_test, outgoing_y_test))\n",
    "\n",
    "    df_features = pd.DataFrame(columns=['Features', 'Importance (Gini Index)'])\n",
    "    df_features['Features'] = columns=vect.get_feature_names()\n",
    "    df_features['Importance (Gini Index)'] = rf.feature_importances_\n",
    "    df_features.sort_values('Importance (Gini Index)', ascending=False, inplace=True)\n",
    "\n",
    "    df_features.head(15)\n",
    "\n",
    "try_vectorizers(random_forest, incoming_X_train, incoming_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Relationships Between Messages\n",
    "\n",
    "### Clustering\n",
    "#### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 20\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(dtm)\n",
    "\n",
    "labels = km.labels_.tolist()\n",
    "df['kmeans-labels'] = labels\n",
    "df.sort_values(by='kmeans-labels')\n",
    "\n",
    "df.groupby('kmeans-labels').incoming.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
